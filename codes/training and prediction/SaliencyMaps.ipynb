{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":290938,"status":"ok","timestamp":1724704839263,"user":{"displayName":"Gergely Szabó","userId":"12741425224045507482"},"user_tz":-120},"id":"W1vA-GZ2C8dL","outputId":"16d99fd4-7dbc-4d50-d8fe-153974827658"},"outputs":[],"source":["#@title Installing necessary libraries, that are not already installed on Colab\n","# This might take a couple of minutes, and it may restart the runtime!\n","# If the runtime requests reloading, canceling is usually the better.\n","# (This might change in the future.)\n","\n","# Detectron2 environment for instance segmentation\n","!pip install \"git+https://github.com/facebookresearch/detectron2.git\"\n","\n","# SMP environment for tracking\n","!pip install segmentation-models-pytorch\n","\n","# Filterpy for Kalman Filter definition (can be ignored, if Kalman Filter reference is not used)\n","!pip install filterpy"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4340,"status":"ok","timestamp":1724704843591,"user":{"displayName":"Gergely Szabó","userId":"12741425224045507482"},"user_tz":-120},"id":"G5gITMd2DJhf"},"outputs":[],"source":["#@title Importing required functions and libraries\n","\n","# Imports from Symmetry-Tracker repo\n","\n","import sys\n","sys.path.append(\"/path/to/symmetry_tracker\")\n","\n","from symmetry_tracker.general_functionalities.video_transformation import TransformVideoFromTIFF\n","\n","from symmetry_tracker.segmentation.segmentator import SingleVideoSegmentation\n","from symmetry_tracker.segmentation.segmentation_io import DisplaySegmentation, WriteSegmentation\n","\n","from symmetry_tracker.tracking.symmetry_tracker import SingleVideoSymmetryTracking\n","from symmetry_tracker.tracking.tracking_io import DisplayTracks, WriteTracks, SaveTracksVideo, SaveTracks, LoadTracks\n","from symmetry_tracker.tracking.post_processing import InterpolateMissingObjects, RemoveShortPaths, HeuristicalEquivalence\n","\n","# Other necessary imports\n","\n","import torch\n","import os\n","import shutil"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1724704843592,"user":{"displayName":"Gergely Szabó","userId":"12741425224045507482"},"user_tz":-120},"id":"wp3k0_oUFsI4"},"outputs":[],"source":["sample_categories = [\"1\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":145646,"status":"ok","timestamp":1724706471270,"user":{"displayName":"Gergely Szabó","userId":"12741425224045507482"},"user_tz":-120},"id":"Tm6HNJQPDM9v","outputId":"adb6634d-f9a9-4872-88d3-03b703bc03ad"},"outputs":[],"source":["#@title Downloading the Models and Sample Data\n","\n","!rm -r downloads\n","!mkdir downloads\n","\n","for sample_category in sample_categories:\n","  sample_record_name = f\"ArrowSynth{sample_category}\"\n","  train_sample_ratio = \"1.0\"\n","  sample_id = \"081\"\n","\n","  !mkdir downloads/$sample_record_name\n","\n","  segmentator_models_dir = f\"/path/to/{sample_record_name}/trained_nets/InstanceSegmentation/\"\n","  segmentator_model_name = f\"model_final.pth\"\n","  segmentator_config_name = \"config.yaml\"\n","\n","  tracking_models_dir = f\"/path/to/{sample_record_name}/trained_nets/LocalTracking/\"\n","  tracking_model_name = f\"{sample_record_name}_[DLV3p,resnet50]_FBtr4_Ep50_Adv2_SR{train_sample_ratio}_NonPretrained_final.pth\"\n","  #tracking_model_name = f\"{sample_record_name}_[DLV3p,resnet50]_FBtr4_Ep50_Adv2_SR{train_sample_ratio}_final.pth\"\n","\n","  testdata_dir = f\"/path/to/{sample_record_name}/data/\"\n","  testdata = f\"{sample_record_name}_test_samples.zip\"\n","\n","  !wget --no-clobber $segmentator_models_dir$segmentator_model_name -P downloads/$sample_record_name/\n","  !wget --no-clobber $segmentator_models_dir$segmentator_config_name -P downloads/$sample_record_name/\n","  !wget --no-clobber $tracking_models_dir$tracking_model_name -P downloads/$sample_record_name/\n","\n","  !mkdir downloads/$sample_record_name/data\n","  !wget --no-clobber $testdata_dir$testdata -P downloads/$sample_record_name/data\n","  !unzip downloads/$sample_record_name/data/$testdata -d downloads/$sample_record_name/data/"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":106,"status":"ok","timestamp":1724705860869,"user":{"displayName":"Gergely Szabó","userId":"12741425224045507482"},"user_tz":-120},"id":"G0Q02yXcH1L_"},"outputs":[],"source":["sample_category = \"1\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":993,"status":"ok","timestamp":1724706280723,"user":{"displayName":"Gergely Szabó","userId":"12741425224045507482"},"user_tz":-120},"id":"BfhutSxlGA1A","outputId":"73298963-07b1-48df-f447-2d27559d4718"},"outputs":[],"source":["#@title Pipeline parameter setup\n","\n","sample_record_name = f\"ArrowSynth{sample_category}\"\n","sample_id = \"081\"\n","train_sample_ratio = \"1.0\"\n","\n","segmentator_model_name = f\"model_final.pth\"\n","segmentator_config_name = \"config.yaml\"\n","tracking_model_name = f\"{sample_record_name}_[DLV3p,resnet50]_FBtr4_Ep50_Adv2_SR{train_sample_ratio}_NonPretrained_final.pth\"\n","#tracking_model_name = f\"{sample_record_name}_[DLV3p,resnet50]_FBtr4_Ep50_Adv2_SR{train_sample_ratio}_final.pth\"\n","\n","# Input paths\n","SegmentationModelPath = f\"./downloads/{sample_record_name}/\"+segmentator_model_name\n","SegmentationModelConfigPath = f\"./downloads/{sample_record_name}/\"+segmentator_config_name\n","TrackingModelPath = f\"./downloads/{sample_record_name}/\"+tracking_model_name\n","InputVideoPath = f\"./downloads/{sample_record_name}/data/{sample_record_name}_test_samples/{sample_id}/imgs/\"\n","\n","# Output paths\n","!mkdir outputs\n","!mkdir outputs/$sample_record_name\n","!mkdir outputs/$sample_record_name/segmentations\n","!mkdir outputs/$sample_record_name/trackings\n","!mkdir outputs/$sample_record_name/videos\n","SegmentationSavePath = f\"./outputs/{sample_record_name}/segmentations/\"+sample_record_name+\"_\"+sample_id+\"_Segmentation.txt\"\n","TrackingSavePath = f\"./outputs/{sample_record_name}/trackings/\"+sample_record_name+\"_\"+sample_id+\"_Tracks.json\"\n","TrackingWritePath = f\"./outputs/{sample_record_name}/trackings/\"+sample_record_name+\"_\"+sample_id+\"_Tracks.txt\"\n","TrackingVideoPath = f\"./outputs/{sample_record_name}/videos/\"+sample_record_name+\"_\"+sample_id+\"_Tracks.mp4\"\n","\n","# TimeKernelSize is the size of the kernel in both directions without the central image\n","# (So if TimeKernelSize is 2, then the full kernel size is 5)\n","# This parameter is unique to the given tracking model\n","TimeKernelSize = 4\n","\n","# Matching colab environment (for now GPU vs CPU)\n","Device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Colab environment: \"+Device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"elapsed":52407,"status":"ok","timestamp":1724705109347,"user":{"displayName":"Gergely Szabó","userId":"12741425224045507482"},"user_tz":-120},"id":"Hl9zVNFPHmpn","outputId":"bfc1f24e-666b-4ff7-80d2-7da0ccaee5dd"},"outputs":[],"source":["#@title Instance Segmentation\n","\n","# Performing segmentation\n","Outmasks = SingleVideoSegmentation(InputVideoPath,\n","                                   SegmentationModelPath,\n","                                   SegmentationModelConfigPath,\n","                                   Device,\n","                                   Color = \"GRAYSCALE\",\n","                                   ScoreThreshold = 0.4)\n","\n","# Displaying segmentation results\n","#DisplaySegmentation(InputVideoPath, Outmasks)\n","\n","# Saving segmentation\n","WriteSegmentation(Outmasks, SegmentationSavePath)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"elapsed":73616,"status":"ok","timestamp":1724705182951,"user":{"displayName":"Gergely Szabó","userId":"12741425224045507482"},"user_tz":-120},"id":"I8yg7C-Rea_w","outputId":"7a39b853-58a5-4095-dc4a-82ec27d72850"},"outputs":[],"source":["#@title Dataloading before Local Tracking\n","\n","import cv2\n","import pandas as pd\n","import numpy as np\n","import pandas as pd\n","from symmetry_tracker.tracking.tracker_utilities import LoadAnnotationDF\n","\n","AnnotPath = SegmentationSavePath\n","\n","VideoFrames = sorted(os.listdir(InputVideoPath))\n","Img0 = cv2.imread(os.path.join(InputVideoPath,VideoFrames[0]))\n","VideoShape = [len(os.listdir(InputVideoPath)), np.shape(Img0)[0], np.shape(Img0)[1]]\n","\n","AnnotDF = LoadAnnotationDF(AnnotPath, VideoShape, MinObjectPixelNumber=20, MaxOverlapRatio=0.5)\n","\n","AnnotDF.to_pickle(\"AnnotDF_Temp.pkl\")"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":445,"status":"ok","timestamp":1724706293290,"user":{"displayName":"Gergely Szabó","userId":"12741425224045507482"},"user_tz":-120},"id":"Km7yXg0aKfuh"},"outputs":[],"source":["#@title Redefining Local Tracking for Saliency Maps\n","\n","import time\n","import cv2\n","import os\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","import gc\n","from scipy.optimize import linear_sum_assignment\n","\n","from symmetry_tracker.general_functionalities.misc_utilities import EncodeMultiRLE, DecodeMultiRLE, OuterBoundingBox, BoxOverlap, dfs\n","from symmetry_tracker.tracking.tracker_metrics import TracksIOU\n","from symmetry_tracker.tracking.tracker_utilities import LoadAnnotationDF, LoadPretrainedModel\n","\n","try:\n","  from IPython.display import display\n","  from symmetry_tracker.general_functionalities.misc_utilities import progress\n","except:\n","  pass\n","\n","from symmetry_tracker.tracking.symmetry_tracker import KernelTrackBbox\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","saliency_temporal_distributions = []\n","saliency_radial_distributions = []\n","\n","def compute_saliency_maps_all_ch(model, input_tensor, marker):\n","    model.eval()\n","    input_tensor.requires_grad_()  # Ensure input_tensor requires gradients\n","\n","    with torch.enable_grad():\n","        output_sm = model(input_tensor)\n","        saliency_maps = torch.zeros_like(input_tensor)  # Assuming input_tensor is (batch_size, channels, H, W)\n","        for i in range(output_sm.size(1)):  # Iterate over output channels\n","            model.zero_grad()\n","            output_sm[:, i, marker[0], marker[1]].backward(retain_graph=True)\n","            saliency_map = input_tensor.grad.abs()\n","            saliency_maps += saliency_map\n","\n","        saliency_maps /= output_sm.size(1)  # Average across all output channels\n","\n","    return saliency_maps\n","\n","def compute_saliency_maps_center_ch(model, input_tensor, marker):\n","    model.eval()\n","    input_tensor.requires_grad_()  # Ensure input_tensor requires gradients\n","\n","    with torch.enable_grad():\n","        output_sm = model(input_tensor)\n","        saliency_maps = torch.zeros_like(input_tensor)  # Assuming input_tensor is (batch_size, channels, H, W)\n","        central_ch = output_sm.size(1)//2+1\n","        model.zero_grad()\n","        output_sm[:, central_ch, marker[0], marker[1]].backward(retain_graph=True)\n","        saliency_map = input_tensor.grad.abs()\n","        saliency_maps += saliency_map\n","\n","    return saliency_maps\n","\n","def calculate_radial_profile(image, marker):\n","    y0, x0 = marker\n","    y, x = np.indices(image.shape)\n","    r = np.sqrt((x - x0)**2 + (y - y0)**2)\n","\n","    r = r.astype(int)\n","    radial_profile = np.bincount(r.ravel(), image.ravel()) / np.bincount(r.ravel())\n","\n","    return radial_profile\n","\n","def KernelTrackBbox_Saliency(LocalVideo, VideoShape, Model, Device, SegmentationConfidence, ObjectBbox):\n","  with torch.no_grad():\n","    inputs = LocalVideo\n","    BboxImg = np.zeros([VideoShape[1],VideoShape[2]])\n","    [x0, y0, x1, y1] = ObjectBbox\n","    BboxImg[x0:x1,y0:y1]=255\n","    inputs = np.append(inputs, [BboxImg], axis=0)\n","    inputs = np.array(inputs, dtype=float)/255\n","    inputs = torch.Tensor(np.array(inputs))\n","\n","    pad_h = (16 - inputs.shape[1] % 16) % 16\n","    pad_w = (16 - inputs.shape[2] % 16) % 16\n","    inputs = F.pad(inputs, (0, pad_w, 0, pad_h), mode='constant', value=0)\n","\n","    inputs=torch.unsqueeze(inputs, dim=0)\n","\n","    inputs=inputs.to(torch.device(Device))\n","    output = np.array(torch.sigmoid(Model(inputs).cpu()))\n","    output = output>SegmentationConfidence\n","    output = output*1.0\n","    output = np.nan_to_num(output, nan=0.0, posinf=1.0, neginf=0.0)\n","\n","    marker = [(x0+x1)//2, (y0+y1)//2]\n","\n","    #saliency_maps = np.array(compute_saliency_maps_all_ch(Model, inputs, marker).cpu())\n","    saliency_maps = np.array(compute_saliency_maps_center_ch(Model, inputs, marker).cpu())\n","\n","    torch.cuda.empty_cache()\n","\n","    n_channels = np.shape(saliency_maps)[1]\n","    max_saliency = np.max(saliency_maps)\n","\n","    saliency_temp_means = []\n","    saliency_radial_means = []\n","    for ch in range(n_channels):\n","      saliency_temp_means.append(np.mean(saliency_maps[0, ch, :, :]))\n","      saliency_radial_means.append(calculate_radial_profile(saliency_maps[0, ch, :, :], marker))\n","\n","\n","    \"\"\"\n","    fig1, ax1 = plt.subplots(1, n_channels, squeeze=False, figsize=[3*n_channels,3])  # Create multiple subplots\n","    fig2, ax2 = plt.subplots(1, n_channels, squeeze=False, figsize=[3*n_channels,3])\n","\n","    for ch in range(n_channels):\n","        saliency_map_ch = saliency_maps[0, ch, :, :]\n","        ax1[0][ch].imshow(saliency_map_ch, cmap='magma', vmin=0, vmax=max_saliency/5)\n","        ax1[0][ch].axis('off')\n","\n","        input_ch = np.array(inputs[0, ch, :, :].cpu())\n","        ax2[0][ch].imshow(input_ch, cmap='gray')\n","        ax2[0][ch].axis('off')\n","    plt.show()\n","    \"\"\"\n","\n","    \"\"\"\n","\n","    sns.barplot(saliency_temp_means)\n","    plt.show()\n","\n","    for ch in range(n_channels):\n","      plt.plot(saliency_radial_means[ch])\n","    plt.show()\n","    \"\"\"\n","\n","    \"\"\"\n","    plt.imshow(output[0, 0, :, :])\n","    plt.show()\n","    \"\"\"\n","\n","    #### GLOBAL VARIABLE ACCESS SECTION ####\n","\n","    saliency_temporal_distributions.append(saliency_temp_means)\n","    saliency_radial_distributions.append(saliency_radial_means)\n","\n","    #### --- ####\n","\n","  return np.array(output[0], dtype = bool)\n","\n","def LocalTracking_Saliency(VideoPath, VideoShape, AnnotDF, Model, Device, TimeKernelSize, Color = \"GRAYSCALE\", Marker = \"BBOX\", SegmentationConfidence = 0.2):\n","\n","  if not Color in [\"GRAYSCALE\", \"RGB\"]:\n","    raise Exception(f\"{Color} is an invalid keyword for Color\")\n","  if not Marker in [\"CENTROID\", \"BBOX\"]:\n","    raise Exception(f\"{Marker} is not an appropriate keyword for Marker\")\n","\n","  VideoFrames = sorted(os.listdir(VideoPath))\n","  NumFrames = len(VideoFrames)\n","\n","  print(\"Local Tracking\")\n","  try:\n","    ProgressBar = display(progress(0, NumFrames), display_id=True)\n","  except:\n","    pass\n","\n","  for Frame in range(NumFrames):\n","    ObjectIDs = AnnotDF.query(\"Frame == @Frame\")[\"ObjectID\"]\n","    for ObjectID in ObjectIDs:\n","\n","      # Input image Composition\n","\n","      if Color == \"GRAYSCALE\":\n","        CentralImg = cv2.imread(os.path.join(VideoPath,VideoFrames[Frame]), cv2.IMREAD_GRAYSCALE)\n","        LocalVideo = np.repeat(CentralImg[np.newaxis, ...], 2*TimeKernelSize+1, axis=0)\n","        for dt in range(-TimeKernelSize, TimeKernelSize+1):\n","          if Frame+dt >= 0 and Frame+dt < NumFrames and dt != 0:\n","            LocalVideo[dt+TimeKernelSize] = cv2.imread(os.path.join(VideoPath,VideoFrames[Frame+dt]), cv2.IMREAD_GRAYSCALE)\n","\n","      elif Color == \"RGB\":\n","        CentralImg = cv2.cvtColor(cv2.imread(os.path.join(VideoPath, VideoFrames[Frame])), cv2.COLOR_BGR2RGB)\n","        CentralImg = np.transpose(CentralImg, (2,0,1))\n","        NumReps = 2*TimeKernelSize+1\n","        LocalVideo = np.zeros((3*NumReps,\n","                       np.shape(CentralImg)[1],\n","                       np.shape(CentralImg)[2]),\n","                      dtype=CentralImg.dtype)\n","        for Rep in range(NumReps):\n","          LocalVideo[3*Rep:3*Rep+3] = CentralImg\n","        for dt in range(-TimeKernelSize, TimeKernelSize+1):\n","          if Frame+dt >= 0 and Frame+dt < NumFrames and dt != 0:\n","            LocalImg = cv2.cvtColor(cv2.imread(os.path.join(VideoPath, VideoFrames[Frame+dt])), cv2.COLOR_BGR2RGB)\n","            LocalVideo[3*(dt+TimeKernelSize):3*(dt+TimeKernelSize)+3] = np.transpose(LocalImg, (2,0,1))\n","\n","      else:\n","        raise Exception(f\"{Color} is an invalid keyword for Color\")\n","\n","      # Local Tracking\n","\n","      LocalTrack = None\n","\n","      \"\"\"\n","      if Marker == \"CENTROID\":\n","        ObjectCenter = AnnotDF.query(\"ObjectID == @ObjectID\")[\"Centroid\"].iloc[0]\n","        LocalTrack = KernelTrackCentroid_Saliency(LocalVideo, VideoShape, Model, Device, SegmentationConfidence, ObjectCenter)\n","      \"\"\"\n","      if Marker == \"CENTROID\":\n","        raise ValueError(\"CENTROID marker does not have saliency maps defined for now\")\n","\n","      elif Marker == \"BBOX\":\n","        ObjectBbox = AnnotDF.query(\"ObjectID == @ObjectID\")[\"SegBbox\"].iloc[0]\n","        #LocalTrack = KernelTrackBbox_Saliency(LocalVideo, VideoShape, Model, Device, SegmentationConfidence, ObjectBbox)\n","\n","        if Frame > TimeKernelSize and Frame < NumFrames-TimeKernelSize:\n","          print(f\"Frame {Frame}\")\n","          print(f\"Tracking Object {ObjectID}\")\n","          LocalTrack = KernelTrackBbox_Saliency(LocalVideo, VideoShape, Model, Device, SegmentationConfidence, ObjectBbox)\n","        else:\n","          LocalTrack = KernelTrackBbox(LocalVideo, VideoShape, Model, Device, SegmentationConfidence, ObjectBbox)\n","\n","\n","      AnnotDF.loc[AnnotDF.query(\"ObjectID == @ObjectID\").index, \"LocalTrackRLE\"] = [EncodeMultiRLE(LocalTrack)]\n","\n","      # 3D Boundary Box calculation\n","\n","      bbox = OuterBoundingBox(LocalTrack)\n","      AnnotDF.loc[AnnotDF.query(\"ObjectID == @ObjectID\").index, \"TrackBbox\"] = [bbox]\n","\n","\n","    #### EARLY STOP ####\n","    if Frame - TimeKernelSize >= 10:\n","      return AnnotDF\n","\n","    try:\n","      ProgressBar.update(progress(Frame, NumFrames))\n","    except:\n","      pass\n","\n","  try:\n","    ProgressBar.update(progress(1, 1))\n","  except:\n","    pass\n","\n","  return AnnotDF"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"swrC3tkPHpWv","outputId":"2eecb20a-a29e-4926-e0f3-a4d549ebfc55"},"outputs":[],"source":["#@title Local Tracking with Saliency Maps\n","\n","AnnotDF = pd.read_pickle(\"AnnotDF_Temp.pkl\")\n","\n","Model = LoadPretrainedModel(TrackingModelPath, Device)\n","AnnotDF = LocalTracking_Saliency(InputVideoPath,\n","                        VideoShape,\n","                        AnnotDF,\n","                        Model,\n","                        Device,\n","                        TimeKernelSize = TimeKernelSize,\n","                        Color = \"GRAYSCALE\",\n","                        Marker = \"BBOX\",\n","                        SegmentationConfidence = 0.2)\n","del Model\n","gc.collect()"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":610,"status":"ok","timestamp":1724706163367,"user":{"displayName":"Gergely Szabó","userId":"12741425224045507482"},"user_tz":-120},"id":"jDbT82ilTaff"},"outputs":[],"source":["# Save distributions to pickle\n","\n","import pickle\n","\n","with open(f'saliency_central_temporal_distributions_AS{sample_category}_F10.pkl', 'wb') as f:\n","    pickle.dump(saliency_temporal_distributions, f)\n","    f.close()\n","\n","with open(f'saliency_central_radial_distributions_AS{sample_category}_F10.pkl', 'wb') as f:\n","    pickle.dump(saliency_radial_distributions, f)\n","    f.close()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPMTo9QjJMuccOGavGbxEh6","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
